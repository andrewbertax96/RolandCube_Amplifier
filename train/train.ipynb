{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChdrlGCt7qhm"
      },
      "source": [
        "\n",
        "# GuitarML Proteus Capture Instructions\n",
        "-------------\n",
        "You will need the \"input.wav\" file from the train directory to re-amp your gear\n",
        "\n",
        "Reamp your pedal, amp, or rig by running this audio signal through your device and record the output. For best results, use a reamp box for pedals and a loadbox for amps (using a mic for amps is also an option). Render the new recording as a WAV file. **Please use 44.1kHz, 16-bit PCM, mono.**\n",
        "Video tutorials are available on [Youtube](https://youtu.be/86oQuYHjpy0).\n",
        "\n",
        "-------------\n",
        "\n",
        "#####  **Step 1**. Click \"Runtime\" in the Colab top menu bar, then \"Change Runtime Type\" and select \"GPU\" and save. You have a limited number of consecutive GPU hours with the free version of Colab, but this will reset in a day or so. \n",
        "\n",
        "#####  **Step 2**. Upload your recorded output from your device by dragging and dropping the \"out.wav\" file to the file browser in the left hand window in Colab. Ensure that this file is named \"out.wav\" for snapshot models. Parameterized capture of a knob requires 5 separate .wav output files, named:\n",
        "       \"out1.wav\", \"out2.wav\", \"out3.wav\", \"out4.wav\", \"out5.wav\"\n",
        "\n",
        "##### **Step 3**. Run the SETUP ENVIRONMENT section by clicking the run arrow on the top left of the box. This should take less than a minute.\n",
        "\n",
        "##### **Step 4**. Choose one (and only one) of the next 4 options as applicable to your captured device. This will begin the model training process. It should take about 10 minutes with GPU runtime selected. The training may finish before reaching 300 epochs, this is normal. Parameterized capture of a full knob will take significantly longer, 30+ minutes.\n",
        "        \n",
        "##### **Step 5**. Run this section to generate a compatible model file. Download from the left hand file browser by right clicking the \"newRolandCubeModel.json\" filename in the left hand menu and selecting \"Download\". May need to refresh the filebrowser by clicking the refresh folder icon.\n",
        "\n",
        "##### **Step 6**. Optionally, generate a plot of the signals to visually see how close the model is to the actual device.\n",
        "\n",
        "------------\n",
        "**Note**: Recommended to \"Disconnect and delete runtime\" from the \"Runtime\" menu and \"Reconnect\" to reset the environment\n",
        "when training additional models. Make sure to download your trained model before disconnecting.\n",
        "\n",
        "**Note**: To continue to refine the model, you may run the same Step 4 (a,b,c) after changing the \"-eps\" field to the number of epochs to continue training. For example, in Step 4c., change \"-eps 300\" to \"-eps 100\" to run an additional 100 epochs. Then re-run Step 5 to generate a new Proteus compatible model. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0YQxFKX8toq"
      },
      "source": [
        "------------\n",
        "### **STEP 3** : SETUP ENVIRONMENT\n",
        "###### Run this block to setup environment. May take a few minutes. Only run this once per Colab session."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pzrdkYdTd3cX"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/GuitarML/Automated-GuitarAmpModelling.git\n",
        "%cd Automated-GuitarAmpModelling/\n",
        "!git checkout proteus-capture\n",
        "!git submodule update --init --recursive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAILgVRX82IJ"
      },
      "source": [
        "------------\n",
        "### **STEP 4a**. Run this to start capture of CLEAN AMP, EDGE OF BREAKUP AMP, or COMPRESSOR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ri7QM2j5ipyb"
      },
      "outputs": [],
      "source": [
        "model=\"amp_clean\"\n",
        "!python prep_wav.py $model -s Data/Proteus_Capture.wav ../out.wav --normalize true\n",
        "!python dist_model_recnet.py -l \"RNN3-\"$model -eps 300"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BfJ72-t288Jx"
      },
      "source": [
        "------------\n",
        "### **STEP 4b**. Run this to start capture of MEDIUM to HIGH GAIN AMP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8DUec-jId3Ti"
      },
      "outputs": [],
      "source": [
        "model=\"amp_gain\"\n",
        "!python prep_wav.py $model -s Data/Proteus_Capture.wav ../out.wav --normalize true\n",
        "!python dist_model_recnet.py -l \"RNN3-\"$model -eps 300"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJYH3YJp88hx"
      },
      "source": [
        "------------\n",
        "### **STEP 4c**.  Run this to start capture of OVERDRIVE, DISTORTION, BOOST PEDAL, or PRE-AMP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Xiq856Ii0ba"
      },
      "outputs": [],
      "source": [
        "model=\"pedal\"\n",
        "!python prep_wav.py $model -s Data/Proteus_Capture.wav ../out.wav --normalize true\n",
        "!python dist_model_recnet.py -l \"RNN3-\"$model -eps 300"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Q7lBR879LQr"
      },
      "source": [
        "------------\n",
        "### **STEP 4d**.  Run this to start capture of a Knob/Control on your amp or pedal (Parameterized Capture)\n",
        "######           This requires 5 separate recordings from a Gain or EQ knob at 5 equal steps, using the Proteus_Capture.wav as input. For example: 0% (or just above 0%), 25%, 50%, 75%, 100% You must upload your five .wav files and re-name them: \n",
        "               \"out1.wav\", \"out2.wav\", \"out3.wav\", \"out4.wav\", \"out5.wav\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8MYDHLNWt64F"
      },
      "outputs": [],
      "source": [
        "model=\"proteus_knob\"\n",
        "!python prep_wav2.py $model -p \"./Configs/Parameterization-Config-Proteus.json\" --normalize true\n",
        "!python dist_model_recnet.py -l \"RNN3-\"$model -is 2 -eps 300"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijHoiPKW9cnm"
      },
      "source": [
        "------------\n",
        "### **STEP 5**. After Above Capture Process is Completed, Run this to generate a compatible model file. \n",
        "######The model file will be located in the top level folder with the name \"newRolandCubeModel.json\" May need to refresh the left hand file browser by clicking the refresh folder icon. Right click the file and choose download, then rename as appropriate.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4ypBZrXi5jM"
      },
      "outputs": [],
      "source": [
        "%cp \"Results/\"$model\"-RNN3-\"$model\"/model_best.json\" ../newRolandCubeModel.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZA_LO7ZV9ovd"
      },
      "source": [
        "------------\n",
        "### **STEP 6**. (Optional) After above Capture Process is completed, Run this to generate graphs of the device model\n",
        "######         The PNG image will be located in the top level folder with the name \"detail_signal_comparison_e2s...\". May need to refresh the left hand file browser by clicking the refresh folder icon. Double click the PNG file to view the graphs. These graphs show approximately 10 milliseconds of audio signal. The top plot shows the input signal. The middle plot shows the target device signal vs the signal predicted by the new model. The goal is for these signals to be as close as possible."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2u4IKm_d3Oh"
      },
      "outputs": [],
      "source": [
        "!python plot.py $model\n",
        "%cp \"Results/\"$model\"-RNN3-\"$model\"/\"$model\"_Detail\"* ../"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5KY3ObN9vfs"
      },
      "source": [
        "------------\n",
        "### TROUBLESHOOTING NOTES\n",
        "\n",
        "1. Training will go through 300 epochs, beginning with a pre-trained starting point model. The number of epochs can be adjusted by changing the \"-eps\" value in the dist_model_recnet.py line on step 4 (a,b,c,d). You can run the same training step again to refine the model, and stop at any time. \n",
        "\n",
        "2. This capture method is limited to non-time based effects (no Delay, Reverb, Flange, Phaser, etc.) It is intended for Amplifiers, Distortion, Overdrive, Boost, Preamps. Results on Compressors vary. The same rules apply for capturing a plugin or other digital audio effect.\n",
        "\n",
        "3. For ideal amplifier capture, record the direct out signal from a load box. Recommended to use a re-amp device when playing the input.wav out of your audio device for impedence matching. \n",
        "\n",
        "4. The final loss values during training should be less than 0.08 to be considered successful. A loss of 0.02 or less is ideal. Higher than 0.10 indicates difficulty in training a model from the device, but note that mic'd amps will typically have a higher loss due to the complexities of the cab/mic. If the loss remains at 0.75 or higher, this could indicate a problem with the out.wav file, either from audio misalignment or error during the upload to Colab. If the latency in your recording is too high (more than 3 milliseconds) use the click around 1 second into the capture WAV to line up your out.wav in your DAW. \n",
        "\n",
        "5. For Parameterized Capture of an amp or pedal knob, if the device knob at 0% means there is no volume out of your device (such as a gain knob on an amplifier), then you should raise it slightly until your hear volume out. The model training doesn't do well if one of the 5 steps is silent.\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Welcome To Colaboratory",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
